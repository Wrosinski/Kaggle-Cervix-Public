{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import misc, ndimage\n",
    "from PIL import Image\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from yolo_utils_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_crops_train(cropped_images, dst, traindf, src = None, augment = False, normalize = False):\n",
    "    pad_col = [0, 0, 0]\n",
    "    saved_imgs = []\n",
    "    crop_filenames = cropped_images['img_name']\n",
    "    labels = cropped_images['class']\n",
    "    labels_set = ['Type_1', 'Type_2', 'Type_3']\n",
    "    cropped_images['class_filename'] = cropped_images.apply(lambda x: x['class'] + '/' + x['img_name'], axis = 1)\n",
    "    \n",
    "    for i in range(len(cropped_images)):\n",
    "        try:\n",
    "            img = ndimage.imread(cropped_images['filename'][i], mode = 'RGB')\n",
    "            x1, x2, y1, y2 = int(cropped_images['x1'][i]), int(cropped_images['x2'][i]), int(cropped_images['y1'][i]), int(cropped_images['y2'][i])\n",
    "            crop_img = img[y1:y2, x1:x2]\n",
    "            h, w = crop_img.shape[0], crop_img.shape[1]\n",
    "        except Exception:\n",
    "            print('Failed for image:', cropped_images['filename'][i])\n",
    "            continue\n",
    "        if h < 30 and w < 30:\n",
    "            continue\n",
    "        else:\n",
    "            if h > w:\n",
    "                crop_img = np.rot90(crop_img)\n",
    "            if h > size[1] and w > size[0]:\n",
    "                res_img = cv2.resize(crop_img, size, cv2.INTER_AREA)\n",
    "                if normalize:\n",
    "                    res_img = normalized(res_img)\n",
    "                try:\n",
    "                    final = Image.fromarray((res_img).astype(np.uint8))\n",
    "                    final.save(dst + '{0}/id{1}_crop_yolo_{2}'.format(labels[i], crop_filenames[i][:-4], str(i) +\n",
    "                                                            '.jpg'))\n",
    "                except Exception:\n",
    "                    print('Saving failed for image: ', crop_filenames[i])\n",
    "            else:\n",
    "                res_img = cv2.resize(crop_img, size, cv2.INTER_CUBIC)\n",
    "                if crop_filenames[i] in saved_imgs:\n",
    "                    continue\n",
    "                else:\n",
    "                    if normalize:\n",
    "                        res_img = normalized(res_img)\n",
    "                    try:\n",
    "                        final = Image.fromarray((res_img).astype(np.uint8))\n",
    "                        final.save(dst + '{0}/id{1}_crop_yolo_{2}'.format(labels[i], crop_filenames[i][:-4], str(i) +\n",
    "                                                                '.jpg'))\n",
    "                    except Exception:\n",
    "                        print('Saving failed for image: ', crop_filenames[i])\n",
    "\n",
    "    def get_orig_imgnames():\n",
    "        orig_imgnames = []\n",
    "        folders = ['Type_1', 'Type_2', 'Type_3']\n",
    "        for fld in folders:\n",
    "            index = folders.index(fld)\n",
    "            print('Load folder {} (Index: {})'.format(fld, index))\n",
    "            dst = os.path.join(src, fld, '*.jpg')\n",
    "            files = glob.glob(dst)\n",
    "            for fl in files:\n",
    "                flbase = fld + '/' + os.path.basename(fl)\n",
    "                orig_imgnames.append(flbase)\n",
    "        return orig_imgnames\n",
    "\n",
    "    def set_diff(normalize = False):\n",
    "        print('Number of test data set difference images:', len(testsetdiff))\n",
    "        for i in testsetdiff:\n",
    "            diff_img = ndimage.imread(src + i, mode = 'RGB')\n",
    "            diff_img_resized = cv2.resize(diff_img, size, cv2.INTER_AREA)\n",
    "            print(i)\n",
    "            if normalize:\n",
    "                diff_img_resized = normalized(diff_img_resized)\n",
    "            final = Image.fromarray((diff_img_resized).astype(np.uint8))\n",
    "            final.save(dst + '{0}/id{1}_original_yolo{2}'.format(i.split('/')[0], i.split('/')[1][:-4], '.jpg'))\n",
    "        return\n",
    "\n",
    "    orig_images_imgnames = get_orig_imgnames()\n",
    "    crop_set = set(cropped_images['class_filename'].tolist())\n",
    "    test_set = set(orig_images_imgnames)\n",
    "    testsetdiff = list(test_set.difference(crop_set))\n",
    "    set_diff()\n",
    "    if augment:\n",
    "        augment_train(dst)\n",
    "        \n",
    "    return \n",
    "\n",
    "def make_crops_test(cropped_images, dst, test = False, src = None, normalize = False):\n",
    "    pad_col = [0, 0, 0]\n",
    "    saved_imgs = []\n",
    "    testfiles = os.listdir(src)\n",
    "    crop_filenames = []\n",
    "    for i in range(len(cropped_images)):\n",
    "        crop_filenames.append(cropped_images['filename'][i].split('/')[-1])\n",
    "    crop_set = set(crop_filenames)\n",
    "    \n",
    "    for i in range(len(cropped_images)):\n",
    "        img = cv2.imread(cropped_images['filename'][i])\n",
    "        dst = dst\n",
    "        if test:\n",
    "            test_filename = cropped_images['filename'][i].split('/')[-1][:-4]\n",
    "            copy_filename = cropped_images['filename'][i].split('/')[-1]\n",
    "        x1, x2, y1, y2 = int(cropped_images['x1'][i]), int(cropped_images['x2'][i]), int(cropped_images['y1'][i]), int(cropped_images['y2'][i])\n",
    "        crop_img = img[y1:y2, x1:x2]\n",
    "        h, w = crop_img.shape[0], crop_img.shape[1]\n",
    "        if h < 30 and w < 30:\n",
    "            print('Crop {} omitted'.format(cropped_images['filename'][i]))\n",
    "            continue\n",
    "        else:\n",
    "            if h > w:\n",
    "                crop_img = np.rot90(crop_img)\n",
    "            if h > size[1] and w > size[0]:\n",
    "                res_img = cv2.resize(crop_img, size, cv2.INTER_AREA)\n",
    "                if normalize:\n",
    "                    res_img = normalized(res_img)\n",
    "                if test:\n",
    "                    cv2.imwrite(dst + test_filename + '_yolo_' + str(i) + '.jpg'  , res_img)\n",
    "                else:\n",
    "                    cv2.imwrite(dst + str(i) + '.jpg', res_img)\n",
    "            else:\n",
    "                res_img = cv2.resize(crop_img, size, cv2.INTER_CUBIC)\n",
    "                if normalize:\n",
    "                    res_img = normalized(res_img)\n",
    "                if test:\n",
    "                    if test_filename in saved_imgs:\n",
    "                        continue\n",
    "                    else:\n",
    "                        cv2.imwrite(dst + test_filename + '_yolo_' + str(i) + '.jpg'  , res_img)\n",
    "                else:\n",
    "                    cv2.imwrite(dst + test_filename + '_yolo_' + str(i) + '.jpg' , res_img)\n",
    "    \n",
    "    \n",
    "    def set_diff(normalize = False):\n",
    "        print('\\n', 'Take set difference between raw images and crops')\n",
    "        test_set = set(testfiles)\n",
    "        testsetdiff = list(test_set.difference(crop_set))\n",
    "        print('Number of test data set difference images:', len(testsetdiff))\n",
    "        for i in testsetdiff:\n",
    "            diff_img = cv2.imread(src + i)\n",
    "            diff_img_resized = cv2.resize(diff_img, size, cv2.INTER_LINEAR)\n",
    "            if normalize:\n",
    "                diff_img_resized = normalized(diff_img_resized)\n",
    "            cv2.imwrite(dst + i[:-4] + '_origtest.jpg', diff_img_resized)\n",
    "        return\n",
    "    \n",
    "    set_diff()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_origpath = '/home/w/Development/darknet/cervix_yolo/train_yolo/'\n",
    "tr_croppath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_crops_yolo_299_normalized/'\n",
    "tr_respath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Old/NCF/darknet2/darknet/Cervix/train_res/train_res100kvoc.txt'\n",
    "\n",
    "te_origpath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test/'\n",
    "te_croppath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test_crops_yolo_299_normalized/'\n",
    "te_respath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Old/NCF/darknet2/darknet/Cervix/test_res/res100kvoc.txt'\n",
    "\n",
    "tradd_origpath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/full_data_renamed/'\n",
    "tradd_croppath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_additional_0.25_crops/'\n",
    "tradd_respath = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Old/NCF/darknet2/darknet/Cervix/train_additional_res/res100kvoc_combined_025.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testdf = load_test(te_origpath)\n",
    "bb_te, co_te = load_boxes(te_respath, testdf)\n",
    "cropte = crop(bb_te)\n",
    "cropte['img_name'] = cropte['filename'].str[-13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindf = load_train(tr_origpath)\n",
    "bb_tr, co_tr = load_boxes(tr_respath, traindf)\n",
    "croptr = crop(bb_tr, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "traindf = load_train(tradd_origpath)\n",
    "bb_tr, co_tr = load_boxes(tradd_respath, traindf)\n",
    "croptr = crop(bb_tr, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_crops(croptr, len(croptr), 5)\n",
    "print_crops(cropte, len(cropte), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_crops/'\n",
    "p2 = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_crops_yolo_299_normalized/'\n",
    "\n",
    "labels_set = ['Type_1', 'Type_2', 'Type_3']\n",
    "make_dirs(p2, labels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = (299, 299)\n",
    "\n",
    "#make_crops_test(cropte, te_croppath, True, te_origpath, normalize = True)\n",
    "make_crops_train(croptr, tr_croppath, traindf, tr_origpath, augment = True, normalize = True)\n",
    "#make_crops_train(croptr, tradd_croppath, traindf, tradd_origpath, augment = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
