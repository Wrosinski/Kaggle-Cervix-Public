{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models import *\n",
    "from models_utils_loading import *\n",
    "from models_utils_fit import *\n",
    "from models_utils_inmem import *\n",
    "from clr_callback import *\n",
    "\n",
    "import inception_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_model(X, X_tr, X_val, y_tr, y_val, modelname = None, checkname = None, load_name = None):\n",
    "    callbacks = [ModelCheckpoint('/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/scripts/models/checks/{}.h5'.format(checkname), \n",
    "                                        monitor='val_loss', \n",
    "                                        verbose = 0, save_best_only = True),\n",
    "                EarlyStopping(monitor='val_loss', patience = 12, verbose = 1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor = 0.4, verbose = 1, \n",
    "                                  patience = 4, min_lr = 5e-6)]\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0.05,\n",
    "                zoom_range=0.15,\n",
    "                rotation_range=180,\n",
    "                width_shift_range=0.05,\n",
    "                height_shift_range=0.05,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True)\n",
    "    train_datagen.fit(X, augment = True)\n",
    "    valid_datagen = ImageDataGenerator(rescale=1./255,)\n",
    "    \n",
    "    if 'res' or 'inception' in checkname:\n",
    "        batch_size = 8\n",
    "    if 'xception' in checkname:\n",
    "        batch_size = 4\n",
    "        \n",
    "    if load_name is not None:\n",
    "        model = load_model(checks_src + load_name)\n",
    "    else:\n",
    "        model = modelname()\n",
    "        \n",
    "    model.fit_generator(train_datagen.flow(X_tr, y_tr, batch_size = batch_size), \n",
    "                        steps_per_epoch = X_tr.shape[0]/batch_size,\n",
    "                        validation_data = valid_datagen.flow(X_val, y_val, batch_size = batch_size, shuffle = False),\n",
    "                        validation_steps = X_val.shape[0]/batch_size, epochs = 200, callbacks = callbacks)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/training_data/'\n",
    "checks_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/scripts/models/checks/'\n",
    "sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/submissions/Raw/'\n",
    "sub_dst = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/submissions/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder Type_1 (Index: 0)\n",
      "Load folder Type_2 (Index: 1)\n",
      "Load folder Type_3 (Index: 2)\n",
      "Read train data time: 10.36 seconds\n",
      "Read train images\n",
      "Load folder Type_1 (Index: 0)\n",
      "Load folder Type_2 (Index: 1)\n",
      "Load folder Type_3 (Index: 2)\n",
      "Read train data time: 9.43 seconds\n",
      "Read train images\n",
      "Load folder Type_1 (Index: 0)\n",
      "Load folder Type_2 (Index: 1)\n",
      "Load folder Type_3 (Index: 2)\n",
      "Read train data time: 0.91 seconds\n",
      "Read test images\n",
      "Read train data time: 3.8 seconds\n"
     ]
    }
   ],
   "source": [
    "X, _, _ = load_train(src + 'train_crops_170epochs/')\n",
    "\n",
    "X_tr, y_tr, train_ids = load_train(src + 'train_set/')\n",
    "y_tr = to_categorical(y_tr)\n",
    "\n",
    "X_val, y_val, train_ids = load_train(src + 'valid_set/')\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "X_test, test_ids = load_test(src + 'test_crops_150epochs/test_crops_150epochs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "173/173 [==============================] - 60s - loss: 1.4468 - acc: 0.4458 - val_loss: 1.7159 - val_acc: 0.4964\n",
      "Epoch 2/200\n",
      "173/173 [==============================] - 51s - loss: 1.2502 - acc: 0.4870 - val_loss: 1.2007 - val_acc: 0.4964\n",
      "Epoch 3/200\n",
      "173/173 [==============================] - 50s - loss: 1.1543 - acc: 0.5065 - val_loss: 1.1623 - val_acc: 0.3650\n",
      "Epoch 4/200\n",
      "173/173 [==============================] - 49s - loss: 1.0565 - acc: 0.5260 - val_loss: 1.5259 - val_acc: 0.2847\n",
      "Epoch 5/200\n",
      "173/173 [==============================] - 49s - loss: 1.0355 - acc: 0.5275 - val_loss: 1.3887 - val_acc: 0.4526\n",
      "Epoch 6/200\n",
      "173/173 [==============================] - 50s - loss: 1.0027 - acc: 0.5723 - val_loss: 0.9809 - val_acc: 0.5474\n",
      "Epoch 7/200\n",
      "173/173 [==============================] - 51s - loss: 0.9987 - acc: 0.5636 - val_loss: 0.8884 - val_acc: 0.5912\n",
      "Epoch 8/200\n",
      "173/173 [==============================] - 49s - loss: 0.9137 - acc: 0.6055 - val_loss: 0.9563 - val_acc: 0.5401\n",
      "Epoch 9/200\n",
      "173/173 [==============================] - 49s - loss: 0.9307 - acc: 0.5867 - val_loss: 0.9048 - val_acc: 0.5766\n",
      "Epoch 10/200\n",
      "173/173 [==============================] - 50s - loss: 0.8781 - acc: 0.6178 - val_loss: 0.7916 - val_acc: 0.6350\n",
      "Epoch 11/200\n",
      "173/173 [==============================] - 49s - loss: 0.9189 - acc: 0.5961 - val_loss: 0.9963 - val_acc: 0.5547\n",
      "Epoch 12/200\n",
      "173/173 [==============================] - 49s - loss: 0.8931 - acc: 0.6315 - val_loss: 1.1281 - val_acc: 0.5328\n",
      "Epoch 13/200\n",
      "173/173 [==============================] - 49s - loss: 0.8738 - acc: 0.6214 - val_loss: 1.1620 - val_acc: 0.5036\n",
      "Epoch 14/200\n",
      "173/173 [==============================] - 49s - loss: 0.8676 - acc: 0.6293 - val_loss: 1.1158 - val_acc: 0.5328\n",
      "Epoch 15/200\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.8784 - acc: 0.6206\n",
      "Epoch 00014: reducing learning rate to 3.9999998989515007e-05.\n",
      "173/173 [==============================] - 49s - loss: 0.8780 - acc: 0.6207 - val_loss: 0.9840 - val_acc: 0.5401\n",
      "Epoch 16/200\n",
      "173/173 [==============================] - 49s - loss: 0.8587 - acc: 0.6445 - val_loss: 1.0499 - val_acc: 0.5182\n",
      "Epoch 17/200\n",
      "173/173 [==============================] - 49s - loss: 0.8152 - acc: 0.6532 - val_loss: 1.0989 - val_acc: 0.5182\n",
      "Epoch 18/200\n",
      "173/173 [==============================] - 49s - loss: 0.8425 - acc: 0.6553 - val_loss: 1.0644 - val_acc: 0.5255\n",
      "Epoch 19/200\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.8725 - acc: 0.6228\n",
      "Epoch 00018: reducing learning rate to 1.5999999595806004e-05.\n",
      "173/173 [==============================] - 49s - loss: 0.8727 - acc: 0.6221 - val_loss: 0.9561 - val_acc: 0.5766\n",
      "Epoch 20/200\n",
      "173/173 [==============================] - 49s - loss: 0.8600 - acc: 0.6474 - val_loss: 0.9391 - val_acc: 0.5693\n",
      "Epoch 21/200\n",
      "173/173 [==============================] - 49s - loss: 0.8021 - acc: 0.6395 - val_loss: 0.9110 - val_acc: 0.5620\n",
      "Epoch 22/200\n",
      "173/173 [==============================] - 49s - loss: 0.7964 - acc: 0.6597 - val_loss: 0.9094 - val_acc: 0.5547\n",
      "Epoch 23/200\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.8168 - acc: 0.6562\n",
      "Epoch 00022: reducing learning rate to 6.399999983841554e-06.\n",
      "173/173 [==============================] - 49s - loss: 0.8192 - acc: 0.6561 - val_loss: 0.9025 - val_acc: 0.5693\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(X, X_tr, X_val, y_tr, y_val, resnet1, 'resnet1adam_patientsplit_0.2_frcnn170e_crops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Epoch 1/200\n",
      "346/346 [==============================] - 112s - loss: 1.4850 - acc: 0.3960 - val_loss: 0.9999 - val_acc: 0.5620\n",
      "Epoch 2/200\n",
      "346/346 [==============================] - 107s - loss: 1.2106 - acc: 0.4465 - val_loss: 0.9754 - val_acc: 0.5182\n",
      "Epoch 3/200\n",
      "346/346 [==============================] - 97s - loss: 1.1149 - acc: 0.4928 - val_loss: 1.0493 - val_acc: 0.4161\n",
      "Epoch 4/200\n",
      "346/346 [==============================] - 98s - loss: 1.1330 - acc: 0.4848 - val_loss: 1.1304 - val_acc: 0.4088\n",
      "Epoch 5/200\n",
      "346/346 [==============================] - 98s - loss: 1.0562 - acc: 0.5325 - val_loss: 1.1010 - val_acc: 0.5109\n",
      "Epoch 6/200\n",
      "346/346 [==============================] - 98s - loss: 1.0301 - acc: 0.5462 - val_loss: 1.0851 - val_acc: 0.5255\n",
      "Epoch 7/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.9850 - acc: 0.5572\n",
      "Epoch 00006: reducing learning rate to 3.9999998989515007e-05.\n",
      "346/346 [==============================] - 99s - loss: 0.9845 - acc: 0.5578 - val_loss: 1.3030 - val_acc: 0.3650\n",
      "Epoch 8/200\n",
      "346/346 [==============================] - 98s - loss: 0.9467 - acc: 0.5737 - val_loss: 1.0458 - val_acc: 0.5693\n",
      "Epoch 9/200\n",
      "346/346 [==============================] - 98s - loss: 0.9712 - acc: 0.5744 - val_loss: 1.0287 - val_acc: 0.5328\n",
      "Epoch 10/200\n",
      "346/346 [==============================] - 98s - loss: 0.9351 - acc: 0.5780 - val_loss: 1.1368 - val_acc: 0.4453\n",
      "Epoch 11/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.9507 - acc: 0.5739\n",
      "Epoch 00010: reducing learning rate to 1.5999999595806004e-05.\n",
      "346/346 [==============================] - 98s - loss: 0.9517 - acc: 0.5737 - val_loss: 0.9997 - val_acc: 0.5182\n",
      "Epoch 12/200\n",
      "346/346 [==============================] - 98s - loss: 0.9283 - acc: 0.5910 - val_loss: 0.9843 - val_acc: 0.5182\n",
      "Epoch 13/200\n",
      "346/346 [==============================] - 108s - loss: 0.9230 - acc: 0.5968 - val_loss: 0.9460 - val_acc: 0.5182\n",
      "Epoch 14/200\n",
      "346/346 [==============================] - 109s - loss: 0.9248 - acc: 0.5802 - val_loss: 0.9340 - val_acc: 0.5328\n",
      "Epoch 15/200\n",
      "346/346 [==============================] - 98s - loss: 0.9054 - acc: 0.5961 - val_loss: 0.9592 - val_acc: 0.5401\n",
      "Epoch 16/200\n",
      "346/346 [==============================] - 98s - loss: 0.9283 - acc: 0.5831 - val_loss: 1.0144 - val_acc: 0.4964\n",
      "Epoch 17/200\n",
      "346/346 [==============================] - 98s - loss: 0.9124 - acc: 0.5896 - val_loss: 1.0302 - val_acc: 0.5036\n",
      "Epoch 18/200\n",
      "346/346 [==============================] - 98s - loss: 0.9117 - acc: 0.5773 - val_loss: 1.0257 - val_acc: 0.4964\n",
      "Epoch 19/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.9113 - acc: 0.5957\n",
      "Epoch 00018: reducing learning rate to 6.399999983841554e-06.\n",
      "346/346 [==============================] - 98s - loss: 0.9128 - acc: 0.5954 - val_loss: 0.9987 - val_acc: 0.5401\n",
      "Epoch 20/200\n",
      "346/346 [==============================] - 98s - loss: 0.9011 - acc: 0.6105 - val_loss: 1.0162 - val_acc: 0.5328\n",
      "Epoch 21/200\n",
      "346/346 [==============================] - 98s - loss: 0.8862 - acc: 0.6033 - val_loss: 1.0100 - val_acc: 0.5255\n",
      "Epoch 22/200\n",
      "346/346 [==============================] - 98s - loss: 0.8992 - acc: 0.6084 - val_loss: 1.0269 - val_acc: 0.5036\n",
      "Epoch 23/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.8761 - acc: 0.6080\n",
      "Epoch 00022: reducing learning rate to 5e-06.\n",
      "346/346 [==============================] - 98s - loss: 0.8790 - acc: 0.6062 - val_loss: 1.0253 - val_acc: 0.5109\n",
      "Epoch 24/200\n",
      "346/346 [==============================] - 98s - loss: 0.9094 - acc: 0.5679 - val_loss: 0.9794 - val_acc: 0.5182\n",
      "Epoch 25/200\n",
      "346/346 [==============================] - 98s - loss: 0.9056 - acc: 0.5882 - val_loss: 0.9913 - val_acc: 0.5182\n",
      "Epoch 26/200\n",
      "346/346 [==============================] - 98s - loss: 0.8950 - acc: 0.6120 - val_loss: 1.0264 - val_acc: 0.4964\n",
      "Epoch 27/200\n",
      "346/346 [==============================] - 98s - loss: 0.8775 - acc: 0.6120 - val_loss: 1.0299 - val_acc: 0.5109\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(X, X_tr, X_val, y_tr, y_val, xception, 'xception_patientsplit_0.2_frcnn170e_crops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "346/346 [==============================] - 86s - loss: 0.8840 - acc: 0.5918 - val_loss: 0.9249 - val_acc: 0.5547\n",
      "Epoch 2/200\n",
      "346/346 [==============================] - 69s - loss: 0.8201 - acc: 0.6286 - val_loss: 1.0067 - val_acc: 0.5401\n",
      "Epoch 3/200\n",
      "346/346 [==============================] - 70s - loss: 0.7634 - acc: 0.6553 - val_loss: 0.8267 - val_acc: 0.5985.655\n",
      "Epoch 4/200\n",
      "346/346 [==============================] - 69s - loss: 0.7465 - acc: 0.6777 - val_loss: 0.9922 - val_acc: 0.5328\n",
      "Epoch 5/200\n",
      "346/346 [==============================] - 69s - loss: 0.6845 - acc: 0.7066 - val_loss: 0.9088 - val_acc: 0.5912\n",
      "Epoch 6/200\n",
      "346/346 [==============================] - 69s - loss: 0.6843 - acc: 0.6980 - val_loss: 0.9326 - val_acc: 0.5839\n",
      "Epoch 7/200\n",
      "346/346 [==============================] - 69s - loss: 0.6683 - acc: 0.7182 - val_loss: 0.8493 - val_acc: 0.6131\n",
      "Epoch 8/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.6374 - acc: 0.7362- ETA:\n",
      "Epoch 00007: reducing learning rate to 3.9999998989515007e-05.\n",
      "346/346 [==============================] - 71s - loss: 0.6385 - acc: 0.7348 - val_loss: 0.8660 - val_acc: 0.5985\n",
      "Epoch 9/200\n",
      "346/346 [==============================] - 69s - loss: 0.6306 - acc: 0.7355 - val_loss: 0.8937 - val_acc: 0.5912\n",
      "Epoch 10/200\n",
      "346/346 [==============================] - 71s - loss: 0.5875 - acc: 0.7601 - val_loss: 0.8021 - val_acc: 0.6496\n",
      "Epoch 11/200\n",
      "346/346 [==============================] - 69s - loss: 0.5960 - acc: 0.7522 - val_loss: 0.8473 - val_acc: 0.6131\n",
      "Epoch 12/200\n",
      "346/346 [==============================] - 69s - loss: 0.5755 - acc: 0.7449 - val_loss: 0.8769 - val_acc: 0.6277 - ac\n",
      "Epoch 13/200\n",
      "346/346 [==============================] - 69s - loss: 0.5674 - acc: 0.7630 - val_loss: 0.8758 - val_acc: 0.6058\n",
      "Epoch 14/200\n",
      "346/346 [==============================] - 69s - loss: 0.5641 - acc: 0.7623 - val_loss: 0.8788 - val_acc: 0.6204\n",
      "Epoch 15/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.7638-  - ETA: 0s - loss: 0.5552 - acc: 0.7645\n",
      "Epoch 00014: reducing learning rate to 1.5999999595806004e-05.\n",
      "346/346 [==============================] - 69s - loss: 0.5543 - acc: 0.7652 - val_loss: 0.8558 - val_acc: 0.6496\n",
      "Epoch 16/200\n",
      "346/346 [==============================] - 69s - loss: 0.5538 - acc: 0.7630 - val_loss: 0.9022 - val_acc: 0.6204 ET\n",
      "Epoch 17/200\n",
      "346/346 [==============================] - 69s - loss: 0.5582 - acc: 0.7738 - val_loss: 0.8953 - val_acc: 0.6204\n",
      "Epoch 18/200\n",
      "346/346 [==============================] - 69s - loss: 0.5411 - acc: 0.7796 - val_loss: 0.9314 - val_acc: 0.6131\n",
      "Epoch 19/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.5415 - acc: 0.7732  ETA: 10s - loss: 0.544 - ETA: 8s - loss: 0. - ETA: 5s - \n",
      "Epoch 00018: reducing learning rate to 6.399999983841554e-06.\n",
      "346/346 [==============================] - 69s - loss: 0.5409 - acc: 0.7738 - val_loss: 0.8970 - val_acc: 0.5985\n",
      "Epoch 20/200\n",
      "346/346 [==============================] - 69s - loss: 0.5377 - acc: 0.7803 - val_loss: 0.9063 - val_acc: 0.6204\n",
      "Epoch 21/200\n",
      "346/346 [==============================] - 69s - loss: 0.5452 - acc: 0.7789 - val_loss: 0.8869 - val_acc: 0.6131\n",
      "Epoch 22/200\n",
      "346/346 [==============================] - 69s - loss: 0.5382 - acc: 0.7738 - val_loss: 0.8810 - val_acc: 0.6131oss: 0.5365 - \n",
      "Epoch 23/200\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.7819- ET\n",
      "Epoch 00022: reducing learning rate to 5e-06.\n",
      "346/346 [==============================] - 69s - loss: 0.5199 - acc: 0.7818 - val_loss: 0.8917 - val_acc: 0.6277\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(X, X_tr, X_val, y_tr, y_val, xception2, 'xception2_patientsplit_0.2_frcnn170e_crops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = fit_model(X, X_tr, X_val, y_tr, y_val, inception1, 'inception1_patientsplit_0.3_origdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = fit_model(X, X_tr, X_val, y_tr, y_val, inception3, 'inception3_patientsplit_0.3_origdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, test_ids = load_test(src + 'test_crops_150epochs/test_crops_150epochs/')\n",
    "model = load_model(checks_src + 'resnet1adam_patientsplit_0.2_frcnn170e_crops.h5')\n",
    "bag_preds = predict_data(model, X_test, 1, 15)\n",
    "submission_inmem(bag_preds, test_ids, 'xception_patientsplit_origdata')\n",
    "prep_sub('xception_patientsplit_origdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
