{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import xgboost as xgb\n",
    "\n",
    "from data_utils import *\n",
    "from fit_utils import *\n",
    "from inmem_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_fold(modelname, layer_index, X = None, X_test = None):\n",
    "    orig_model = load_model(checks_src + '{}.h5'.format(modelname))\n",
    "    m = Model(input = orig_model.input, output = orig_model.layers[layer_index].output)\n",
    "    if X_test is None:\n",
    "        preds = m.predict(X, batch_size = 8)\n",
    "        return preds\n",
    "    if X_test is not None:\n",
    "        preds_test = m.predict(X_test, batch_size = 8)\n",
    "        return preds_test\n",
    "    \n",
    "def submission_inmem(bag_preds, test_ids, name):\n",
    "    print('Begin to write submission file ..')\n",
    "    f_submit = open(os.path.join(sub_src, '{}'.format(name) +'.csv'), 'w')\n",
    "    f_submit.write('image,Type_1,Type_2,Type_3\\n')\n",
    "    for i, image_name in enumerate(test_ids):\n",
    "        pred = ['%.6f' % p for p in bag_preds[i, :]]\n",
    "        if i%100 == 0:\n",
    "            print(i, '/', 600)\n",
    "        f_submit.write('%s,%s\\n' % (os.path.basename(image_name), ','.join(pred)))\n",
    "    f_submit.close()\n",
    "    print('Submission {} written.'.format(name))\n",
    "    return \n",
    "\n",
    "def split_proper_skf(train_ids, num_folds):\n",
    "    folds_train_imgs = []\n",
    "    folds_val_imgs = []\n",
    "    folds_train_inds = []\n",
    "    folds_val_inds = [] \n",
    "    img_names = []\n",
    "    for i in train_ids:\n",
    "        img_names.append(i[:6] + '/' + i.split('_')[1][2:])\n",
    "    img_names = list(set(img_names))\n",
    "    train_ids = np.array(train_ids)\n",
    "    img_names = np.array(img_names)\n",
    "    skf = KFold(n_splits = num_folds, random_state = 111, shuffle = True)\n",
    "    print('Running {}-Fold data split'.format(num_folds))\n",
    "    fold_number = 1\n",
    "    for train_index, test_index in skf.split(img_names):\n",
    "        print('Split dataset for fold:', fold_number)\n",
    "        train_split, val_split = img_names[train_index], img_names[test_index]\n",
    "        to_train = []\n",
    "        for orig in train_ids:\n",
    "            for tr in train_split:\n",
    "                if tr in orig:\n",
    "                    to_train.append(orig)\n",
    "        to_train = list(set(to_train))\n",
    "        to_val = list(set(train_ids).difference(set(to_train)))\n",
    "        folds_train_imgs.append(to_train)\n",
    "        folds_val_imgs.append(to_val)\n",
    "        print('Number of training set images: {}, validation set images: {}'.format(len(to_train), len(to_val)))\n",
    "        inds_train = []\n",
    "        inds_val = []\n",
    "        for i, val in enumerate(train_ids):\n",
    "            for j in to_train:\n",
    "                if j in val:\n",
    "                    inds_train.append(i)\n",
    "        inds_val = list(set(range(len(train_ids))).difference(set(inds_train)))\n",
    "        folds_train_inds.append(inds_train)\n",
    "        folds_val_inds.append(inds_val)\n",
    "        fold_number += 1\n",
    "    return folds_train_imgs, folds_val_imgs, folds_train_inds, folds_val_inds\n",
    "    \n",
    "    \n",
    "def fit_xgb(X, num_folds, layer_index, checkname = None, X_test = None):\n",
    "    folds_train_imgs, folds_val_imgs, folds_train_inds, folds_val_inds = split_proper_skf(train_ids, num_folds)\n",
    "    params = {\n",
    "        'seed': 0,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'silent': 1,\n",
    "        'subsample': 0.7,\n",
    "        'learning_rate': 0.03,\n",
    "        'objective': 'reg:linear',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 3,\n",
    "        'max_depth': 12,\n",
    "        'min_child_weight': 100,\n",
    "        'booster': 'gbtree',\n",
    "        }\n",
    "    test_predictions = []\n",
    "    #for i in range(len(folds_train_inds)):\n",
    "    for i in range(6):\n",
    "        print('Extracting features and training for fold:', i + 1)\n",
    "        X_tr = X[folds_train_inds[i]]\n",
    "        X_val = X[folds_val_inds[i]]\n",
    "        y_tr = y[folds_train_inds[i]]\n",
    "        y_val = y[folds_val_inds[i]]\n",
    "        X_tr = extract_features_fold('{}_fold{}'.format(checkname, i + 1), layer_index, X_tr)\n",
    "        X_val = extract_features_fold('{}_fold{}'.format(checkname, i + 1), layer_index, X_val)\n",
    "        d_train = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        d_valid = xgb.DMatrix(X_val, label=y_val)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'eval')]\n",
    "\n",
    "        clf = xgb.train(params, d_train, 100000, watchlist, early_stopping_rounds = 50,\n",
    "                       verbose_eval = 50)\n",
    "        preds_val = clf.predict(xgb.DMatrix(X_val), ntree_limit=clf.best_ntree_limit)\n",
    "        print('Logloss:', log_loss(y_val, preds_val))\n",
    "        if X_test is not None:\n",
    "            X_test_feats = extract_features_fold('{}_fold{}'.format(checkname, i + 1), layer_index, X_test = X_test)\n",
    "            preds_test = clf.predict(xgb.DMatrix(X_test_feats), ntree_limit=clf.best_ntree_limit)\n",
    "            test_predictions.append(preds_test)\n",
    "    return np.array(test_predictions).mean(axis = 0)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/training_data/'\n",
    "checks_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/scripts/models/checks/'\n",
    "sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/submissions/Raw/'\n",
    "sub_dst = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/submissions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder Type_1 (Index: 0)\n",
      "Load folder Type_2 (Index: 1)\n",
      "Load folder Type_3 (Index: 2)\n",
      "Read train data time: 3.89 seconds\n",
      "Read test images\n",
      "Read train data time: 2.07 seconds\n"
     ]
    }
   ],
   "source": [
    "X, y, train_ids = load_train(src + 'train_crops_yolo_299/')\n",
    "X = X / 255.\n",
    "\n",
    "X_test, test_ids = load_test(src + 'test_crops_yolo_299/test_crops_yolo_299/')\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_xgb(X, 10, -2, 'xception2_10foldSKF_yolo299')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10-Fold data split\n",
      "Split dataset for fold: 1\n",
      "Number of training set images: 1849, validation set images: 87\n",
      "Split dataset for fold: 2\n",
      "Number of training set images: 1872, validation set images: 64\n",
      "Split dataset for fold: 3\n",
      "Number of training set images: 1862, validation set images: 74\n",
      "Split dataset for fold: 4\n",
      "Number of training set images: 1862, validation set images: 74\n",
      "Split dataset for fold: 5\n",
      "Number of training set images: 1845, validation set images: 91\n",
      "Split dataset for fold: 6\n",
      "Number of training set images: 1873, validation set images: 63\n",
      "Split dataset for fold: 7\n",
      "Number of training set images: 1868, validation set images: 68\n",
      "Split dataset for fold: 8\n",
      "Number of training set images: 1866, validation set images: 70\n",
      "Split dataset for fold: 9\n",
      "Number of training set images: 1873, validation set images: 63\n",
      "Split dataset for fold: 10\n",
      "Number of training set images: 1830, validation set images: 106\n",
      "Extracting features and training for fold: 1\n",
      "[0]\ttrain-mlogloss:1.084\teval-mlogloss:1.08843\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.725434\teval-mlogloss:0.853818\n",
      "[100]\ttrain-mlogloss:0.612889\teval-mlogloss:0.790479\n",
      "[150]\ttrain-mlogloss:0.560002\teval-mlogloss:0.765446\n",
      "[200]\ttrain-mlogloss:0.528296\teval-mlogloss:0.746635\n",
      "[250]\ttrain-mlogloss:0.506445\teval-mlogloss:0.734947\n",
      "[300]\ttrain-mlogloss:0.487155\teval-mlogloss:0.724758\n",
      "[350]\ttrain-mlogloss:0.470462\teval-mlogloss:0.719603\n",
      "[400]\ttrain-mlogloss:0.4559\teval-mlogloss:0.713848\n",
      "[450]\ttrain-mlogloss:0.442173\teval-mlogloss:0.709512\n",
      "[500]\ttrain-mlogloss:0.429703\teval-mlogloss:0.707406\n",
      "[550]\ttrain-mlogloss:0.417831\teval-mlogloss:0.703849\n",
      "[600]\ttrain-mlogloss:0.40665\teval-mlogloss:0.70428\n",
      "Stopping. Best iteration:\n",
      "[567]\ttrain-mlogloss:0.413917\teval-mlogloss:0.700868\n",
      "\n",
      "Logloss: 0.700867611744\n",
      "Extracting features and training for fold: 2\n",
      "[0]\ttrain-mlogloss:1.08286\teval-mlogloss:1.08951\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.70142\teval-mlogloss:0.867521\n",
      "[100]\ttrain-mlogloss:0.583573\teval-mlogloss:0.803044\n",
      "[150]\ttrain-mlogloss:0.529937\teval-mlogloss:0.777792\n",
      "[200]\ttrain-mlogloss:0.49759\teval-mlogloss:0.777827\n",
      "Stopping. Best iteration:\n",
      "[172]\ttrain-mlogloss:0.514371\teval-mlogloss:0.774015\n",
      "\n",
      "Logloss: 0.774015316623\n",
      "Extracting features and training for fold: 3\n",
      "[0]\ttrain-mlogloss:1.08554\teval-mlogloss:1.08819\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.754457\teval-mlogloss:0.848017\n",
      "[100]\ttrain-mlogloss:0.646143\teval-mlogloss:0.768751\n",
      "[150]\ttrain-mlogloss:0.592193\teval-mlogloss:0.726542\n",
      "[200]\ttrain-mlogloss:0.557648\teval-mlogloss:0.696952\n",
      "[250]\ttrain-mlogloss:0.532999\teval-mlogloss:0.685863\n",
      "[300]\ttrain-mlogloss:0.513168\teval-mlogloss:0.679019\n",
      "[350]\ttrain-mlogloss:0.495908\teval-mlogloss:0.669298\n",
      "[400]\ttrain-mlogloss:0.480426\teval-mlogloss:0.664908\n",
      "[450]\ttrain-mlogloss:0.466516\teval-mlogloss:0.659452\n",
      "[500]\ttrain-mlogloss:0.453829\teval-mlogloss:0.657061\n",
      "[550]\ttrain-mlogloss:0.441499\teval-mlogloss:0.65777\n",
      "Stopping. Best iteration:\n",
      "[513]\ttrain-mlogloss:0.450777\teval-mlogloss:0.656168\n",
      "\n",
      "Logloss: 0.65616769477\n",
      "Extracting features and training for fold: 4\n",
      "[0]\ttrain-mlogloss:1.08793\teval-mlogloss:1.09523\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.811583\teval-mlogloss:0.985523\n",
      "[100]\ttrain-mlogloss:0.712096\teval-mlogloss:0.947232\n",
      "[150]\ttrain-mlogloss:0.658025\teval-mlogloss:0.927358\n",
      "[200]\ttrain-mlogloss:0.620231\teval-mlogloss:0.918675\n",
      "[250]\ttrain-mlogloss:0.591761\teval-mlogloss:0.915902\n",
      "[300]\ttrain-mlogloss:0.567383\teval-mlogloss:0.908939\n",
      "[350]\ttrain-mlogloss:0.546446\teval-mlogloss:0.907182\n",
      "[400]\ttrain-mlogloss:0.526979\teval-mlogloss:0.90518\n",
      "[450]\ttrain-mlogloss:0.509615\teval-mlogloss:0.909811\n",
      "Stopping. Best iteration:\n",
      "[411]\ttrain-mlogloss:0.523009\teval-mlogloss:0.904053\n",
      "\n",
      "Logloss: 0.904053134491\n",
      "Extracting features and training for fold: 5\n",
      "[0]\ttrain-mlogloss:1.08061\teval-mlogloss:1.08736\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.651163\teval-mlogloss:0.816147\n",
      "[100]\ttrain-mlogloss:0.516889\teval-mlogloss:0.738943\n",
      "[150]\ttrain-mlogloss:0.458008\teval-mlogloss:0.709335\n",
      "[200]\ttrain-mlogloss:0.42348\teval-mlogloss:0.682903\n",
      "[250]\ttrain-mlogloss:0.399032\teval-mlogloss:0.67015\n",
      "[300]\ttrain-mlogloss:0.379384\teval-mlogloss:0.665565\n",
      "[350]\ttrain-mlogloss:0.364145\teval-mlogloss:0.661247\n",
      "[400]\ttrain-mlogloss:0.35122\teval-mlogloss:0.663121\n",
      "Stopping. Best iteration:\n",
      "[353]\ttrain-mlogloss:0.36337\teval-mlogloss:0.660934\n",
      "\n",
      "Logloss: 0.660933657539\n",
      "Extracting features and training for fold: 6\n",
      "[0]\ttrain-mlogloss:1.08469\teval-mlogloss:1.08689\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.731268\teval-mlogloss:0.771744\n",
      "[100]\ttrain-mlogloss:0.612153\teval-mlogloss:0.642492\n",
      "[150]\ttrain-mlogloss:0.55567\teval-mlogloss:0.569992\n",
      "[200]\ttrain-mlogloss:0.52309\teval-mlogloss:0.535\n",
      "[250]\ttrain-mlogloss:0.500203\teval-mlogloss:0.514317\n",
      "[300]\ttrain-mlogloss:0.482688\teval-mlogloss:0.497373\n",
      "[350]\ttrain-mlogloss:0.467192\teval-mlogloss:0.48943\n",
      "[400]\ttrain-mlogloss:0.45378\teval-mlogloss:0.481381\n",
      "[450]\ttrain-mlogloss:0.441065\teval-mlogloss:0.477186\n",
      "[500]\ttrain-mlogloss:0.429516\teval-mlogloss:0.472136\n",
      "[550]\ttrain-mlogloss:0.418434\teval-mlogloss:0.468999\n",
      "[600]\ttrain-mlogloss:0.408316\teval-mlogloss:0.467034\n",
      "[650]\ttrain-mlogloss:0.398419\teval-mlogloss:0.464645\n",
      "[700]\ttrain-mlogloss:0.389188\teval-mlogloss:0.46257\n",
      "[750]\ttrain-mlogloss:0.380059\teval-mlogloss:0.460494\n",
      "[800]\ttrain-mlogloss:0.371469\teval-mlogloss:0.46044\n",
      "Stopping. Best iteration:\n",
      "[758]\ttrain-mlogloss:0.378493\teval-mlogloss:0.4595\n",
      "\n",
      "Logloss: 0.459499629362\n",
      "Begin to write submission file ..\n",
      "0 / 600\n",
      "100 / 600\n",
      "200 / 600\n",
      "300 / 600\n",
      "400 / 600\n",
      "500 / 600\n",
      "600 / 600\n",
      "700 / 600\n",
      "800 / 600\n",
      "Submission XGB_on_xception2_10foldSKF_yolo299 written.\n",
      "Saving crops only predictions.\n",
      "Index(['Type_1', 'Type_2', 'Type_3', 'image_name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_preds = fit_xgb(X, 10, -2, 'xception2_10foldSKF_yolo299', X_test = X_test)\n",
    "submission_inmem(test_preds, test_ids, 'XGB_on_xception2_10foldSKF_yolo299')\n",
    "prep_sub('XGB_on_xception2_10foldSKF_yolo299')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "r1_train, r1_val = extract_features('resnet1adam_origdata', -5, X_tr, X_val)\n",
    "x1_train, x1_val = extract_features('xception_origdata', -5, X_tr, X_val)\n",
    "\n",
    "r1_test = extract_features('resnet1adam_origdata', -5, X_test = X_test)\n",
    "x1_test = extract_features('xception_origdata', -5, X_test = X_test)\n",
    "\n",
    "xgb_train = np.concatenate((r1_train, x1_train), axis = 1)\n",
    "xgb_val = np.concatenate((r1_val, x1_val), axis = 1)\n",
    "xgb_test = np.concatenate((r1_test, x1_test), axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
