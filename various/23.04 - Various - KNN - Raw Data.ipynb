{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/w/anaconda3/envs/idp3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Reshape, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adadelta, Adam, SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import shutil\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import numpy as np\n",
    "from various_utils_general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test images\n",
      "Resized test data time: 65.24 seconds\n"
     ]
    }
   ],
   "source": [
    "srcvgg = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test_crops_vgg/'\n",
    "dstvgg = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/training_data/test_crops_vgg_299/test_crops_vgg_299/'\n",
    "resize_test(srcvgg, dstvgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prep_test(te_path):\n",
    "    t = time.time()\n",
    "    X_test, test_ids = load_test(te_path)\n",
    "    X_test2 = X_test.astype('float32')\n",
    "    X_test2 = preprocess_input(X_test2)\n",
    "    features = model.predict(X_test2)\n",
    "    features = features.reshape(len(X_test2), -1)\n",
    "    print('Reshaped: ', features.shape)\n",
    "    print('Time it took to prepare test data:', time.time() - t)\n",
    "    return X_test2, test_ids, features\n",
    "\n",
    "def prep_train(tr_path):\n",
    "    t = time.time()\n",
    "    X_train, y_train, train_ids = load_train(tr_path)\n",
    "    X_train2 = X_train.astype('float32')\n",
    "    X_train2 = preprocess_input(X_train2)\n",
    "    features = model.predict(X_train2, batch_size = 16)\n",
    "    features = features.reshape(len(X_train2), -1)\n",
    "    print('Reshaped: ', features.shape)\n",
    "    print('Time it took to prepare test data:', time.time() - t)\n",
    "    return X_train, y_train, train_ids, features\n",
    "\n",
    "\n",
    "def fit_knn(neighs, features):\n",
    "    knn = NearestNeighbors(n_neighbors = neighs, n_jobs = 6, metric = 'hamming', algorithm = 'brute')\n",
    "    knn.fit(features)\n",
    "    neighbors = knn.kneighbors(features)\n",
    "    return neighbors\n",
    "\n",
    "def normalize_probs(df):\n",
    "    df2 = df.copy().iloc[:, :-1]\n",
    "    df3 = df.copy().iloc[:, :-1]\n",
    "    for i in df2.columns:\n",
    "        df3[i] = df2[i] / df2.sum(axis = 1)\n",
    "    return df3\n",
    "\n",
    "def get_averaged(neighbors):\n",
    "    neigh = fit_knn(neighbors, features_test)\n",
    "    sub_knn = nn_probs(neigh)\n",
    "    sub_knn = normalize_probs(sub_knn)\n",
    "    sub_knn['image'] = sub1['image']\n",
    "    return sub_knn\n",
    "\n",
    "\n",
    "def get_similar(neighbors_list, threshold, savename):\n",
    "    imgs = []\n",
    "    for i in range(len(neighbors_list[0])):\n",
    "        for j in range(1, neighbors_list[0].shape[1]):\n",
    "            if abs(neighbors_list[0][i][0] - neighbors_list[0][i][j]) <= threshold and abs(neighbors_list[0][i][0] - neighbors_list[0][i][j]) >= 0.0001:\n",
    "                print('Image index:', neighbors_list[1][i][j])\n",
    "                #print('Distances:', neighbors_list[0][i])\n",
    "                #print('Neighbors:', neighbors_list[1][i])\n",
    "                imgs.append(neighbors_list[1][i][j])\n",
    "    imgs = list(set(imgs))\n",
    "    imgs_todel = []\n",
    "    for i in imgs:\n",
    "        imgs_todel.append(train_ids[i])\n",
    "        with open('{}.txt'.format(savename), 'a') as out:\n",
    "            out.write(train_ids[i] + '\\n')\n",
    "    return imgs_todel\n",
    "\n",
    "def delete_similar(src, imgstodel):\n",
    "    folders = ['Type_1', 'Type_2', 'Type_3']\n",
    "    dst = src + 'to_delete/'\n",
    "    if 'to_delete/' not in os.listdir(src):\n",
    "        os.mkdir(src + 'to_delete/')\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join(src, fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for todel in imgstodel:\n",
    "            for fl in files:\n",
    "                if todel in fl:\n",
    "                    flbase = os.path.basename(fl)\n",
    "                    shutil.move(fl, dst + flbase)\n",
    "    return\n",
    "               \n",
    "def show_neighbors(X, neighbors, index, index2):\n",
    "    print(neighbors[0][index])\n",
    "    print(neighbors[1][index])\n",
    "    fig, ax = plt.subplots(1,2, figsize = (20, 12))\n",
    "    ax[0].imshow(X[index])\n",
    "    ax[1].imshow(X[index2])\n",
    "    return\n",
    "    \n",
    "tr_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train/'\n",
    "te_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test/'\n",
    "tradd_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_additional/'\n",
    "\n",
    "base_model = VGG19(weights='imagenet', include_top = False, input_shape = (299, 299, 3))\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('block5_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_train(src, dst):\n",
    "    start_time = time.time()\n",
    "    print('Read train images')\n",
    "    folders = ['Type_1', 'Type_2', 'Type_3']\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join(src, fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for i, fl in enumerate(files):\n",
    "            flbase = os.path.basename(fl)\n",
    "            flbase = '{}/id{}_vgg11_{}'.format(fld, flbase.split('.')[0], i) + '.jpg'\n",
    "            try:\n",
    "                img = get_im_cv2(fl)\n",
    "            except Exception:\n",
    "                print('Failed for image:', fl)\n",
    "                continue\n",
    "            res_img = cv2.resize(img, size, cv2.INTER_AREA)\n",
    "            final = Image.fromarray((res_img).astype(np.uint8))\n",
    "            final.save(dst + flbase)\n",
    "    print('Resized train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_te = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test_crops_vgg_299/'\n",
    "resize_test(te_path, dst_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_crops_vgg11/'\n",
    "dst = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_crops_vgg11_299/'\n",
    "resize_train(tr_path, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, train_ids, features = prep_train(tr_path)\n",
    "np.save('raw_original_resized', X_train)\n",
    "np.save('raw_original_features', features)\n",
    "np.save('raw_original_ids', train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, test_ids, features = prep_test(te_path)\n",
    "np.save('raw_test_resized', X_train)\n",
    "np.save('raw_test_features', features)\n",
    "np.save('raw_test_ids', test_ids)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = np.load('raw_original_resized.npy')\n",
    "features_train = np.load('raw_original_features.npy')\n",
    "\n",
    "X_train_add = np.load('raw_additional_resized.npy')\n",
    "features_train_add = np.load('raw_additional_features.npy')\n",
    "\n",
    "X_test = np.load('raw_test_resized.npy')\n",
    "features_test = np.load('raw_test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_knn(neighs, features):\n",
    "    knn = NearestNeighbors(n_neighbors = neighs, n_jobs = 6, metric = 'chebyshev', algorithm = 'brute')\n",
    "    knn.fit(features)\n",
    "    neighbors = knn.kneighbors(features)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n3 = fit_knn(3, features)\n",
    "#n5 = fit_knn(5, features)\n",
    "n8 = fit_knn(8, features_train_add)\n",
    "#n8te = fit_knn(8, features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation, thres = 3e-01, maybe 4e-01 seems to give good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgstodel_trorig = get_similar(n8, 3e-01, 'additonaltrain_raw_0.3_correlationdist')\n",
    "#delete_similar(tr_path, imgstodel_trorig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgstodel_teorig = get_similar(n8te, 0.4, 'similar_original_test_0.4')\n",
    "#delete_similar(te_path, imgstodel_teorig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "te_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test/'\n",
    "dst = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test_resized/'\n",
    "resize_test(te_path, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
