{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Reshape, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adadelta, Adam, SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import shutil\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import numpy as np\n",
    "from various_utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_test(te_path):\n",
    "    t = time.time()\n",
    "    X_test, test_ids = load_test(te_path)\n",
    "    X_test2 = X_test.astype('float32')\n",
    "    X_test2 = preprocess_input(X_test2)\n",
    "    features = model.predict(X_test2)\n",
    "    features = features.reshape(len(X_test2), -1)\n",
    "    print('Reshaped: ', features.shape)\n",
    "    print('Time it took to prepare test data:', time.time() - t)\n",
    "    return X_test2, test_ids, features\n",
    "\n",
    "def prep_train(tr_path):\n",
    "    t = time.time()\n",
    "    X_train, y_train, train_ids = load_train(tr_path)\n",
    "    X_train2 = X_train.astype('float32')\n",
    "    X_train2 = preprocess_input(X_train2)\n",
    "    features = model.predict(X_train2, batch_size = 16)\n",
    "    features = features.reshape(len(X_train2), -1)\n",
    "    print('Reshaped: ', features.shape)\n",
    "    print('Time it took to prepare train data:', time.time() - t)\n",
    "    return X_train, y_train, train_ids, features\n",
    "\n",
    "\n",
    "def fit_knn(neighs, features):\n",
    "    knn = NearestNeighbors(n_neighbors = neighs, n_jobs = 6, metric = 'cosine', algorithm = 'brute')\n",
    "    knn.fit(features)\n",
    "    neighbors = knn.kneighbors(features)\n",
    "    return neighbors\n",
    "\n",
    "def normalize_probs(df):\n",
    "    df2 = df.copy().iloc[:, :-1]\n",
    "    df3 = df.copy().iloc[:, :-1]\n",
    "    for i in df2.columns:\n",
    "        df3[i] = df2[i] / df2.sum(axis = 1)\n",
    "    return df3\n",
    "\n",
    "def get_averaged(neighbors):\n",
    "    neigh = fit_knn(neighbors, features_test)\n",
    "    sub_knn = nn_probs(neigh)\n",
    "    sub_knn = normalize_probs(sub_knn)\n",
    "    sub_knn['image'] = sub1['image']\n",
    "    return sub_knn\n",
    "\n",
    "\n",
    "def get_similar(neighbors_list, threshold, savename):\n",
    "    imgs = []\n",
    "    for i in range(len(neighbors_list[0])):\n",
    "        for j in range(1, neighbors_list[0].shape[1]):\n",
    "            if abs(neighbors_list[0][i][0] - neighbors_list[0][i][j]) <= threshold and abs(neighbors_list[0][i][0] - neighbors_list[0][i][j]) >= 0.0001:\n",
    "                print('Image index:', neighbors_list[1][i][j])\n",
    "                #print('Distances:', neighbors_list[0][i])\n",
    "                #print('Neighbors:', neighbors_list[1][i])\n",
    "                imgs.append(neighbors_list[1][i][j])\n",
    "    imgs = list(set(imgs))\n",
    "    imgs_todel = []\n",
    "    for i in imgs:\n",
    "        imgs_todel.append(train_ids[i])\n",
    "        with open('{}.txt'.format(savename), 'a') as out:\n",
    "            out.write(train_ids[i] + '\\n')\n",
    "    return imgs_todel\n",
    "\n",
    "def delete_similar(src, imgstodel):\n",
    "    folders = ['Type_1', 'Type_2', 'Type_3']\n",
    "    dst = src + 'to_delete/'\n",
    "    if 'to_delete' not in os.listdir(src):\n",
    "        os.mkdir(src + 'to_delete')\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join(src, fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for todel in imgstodel:\n",
    "            for fl in files:\n",
    "                if todel in fl:\n",
    "                    flbase = os.path.basename(fl)\n",
    "                    shutil.move(fl, dst + flbase)\n",
    "    return\n",
    "               \n",
    "def show_neighbors(index, index2):\n",
    "    print(n8[0][index])\n",
    "    print(n8[1][index])\n",
    "    fig, ax = plt.subplots(1,2, figsize = (20, 12))\n",
    "    ax[0].imshow(X_train[index])\n",
    "    ax[1].imshow(X_train[index2])\n",
    "    return\n",
    "    \n",
    "tr_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train/'\n",
    "te_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/test/'\n",
    "tradd_path = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Intel_Cervix/data/train_additional_0.25_crops/'\n",
    "\n",
    "base_model = VGG19(weights='imagenet', include_top = False, input_shape = (299, 299, 3))\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('block5_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, train_ids, features = prep_train(tradd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n3 = fit_knn(3, features)\n",
    "#n5 = fit_knn(5, features)\n",
    "n8 = fit_knn(8, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_neighbors(651, 386)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgstodel = get_similar(n8, 0.3, 'similar_combinedcrops_0.3_filtered')\n",
    "delete_similar(tradd_path, imgstodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
